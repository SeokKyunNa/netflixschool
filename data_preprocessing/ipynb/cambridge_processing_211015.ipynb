{"cells":[{"cell_type":"markdown","metadata":{"id":"rloP9MUUtsIH"},"source":["## 라이브러리"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1634204559760,"user":{"displayName":"engs","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04651459774485874353"},"user_tz":-540},"id":"cpNvCuSDtsIM"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import os"]},{"cell_type":"markdown","metadata":{"id":"UECFahEa9L8r"},"source":["## path 설정"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1634204559761,"user":{"displayName":"engs","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04651459774485874353"},"user_tz":-540},"id":"N1HL8ea99LeL"},"outputs":[],"source":["path = '..'\n","camb_word_path = f'{path}/words/raw_word_data/new'\n","origin_word_path = f'{path}/words/final_datasets'"]},{"cell_type":"markdown","metadata":{"id":"9yKy7SvwtsIO"},"source":["## 결과 데이터프레임 "]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":468},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1634204559764,"user":{"displayName":"engs","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04651459774485874353"},"user_tz":-540},"id":"a844L_F4tsIP","outputId":"a01c940a-09e0-4316-eb72-55db1aeeb2a2"},"outputs":[{"name":"stdout","output_type":"stream","text":["../words/final_datasets/words_levels_df.csv\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>oxford_level</th>\n","      <th>oxford_version</th>\n","      <th>lexile_grade</th>\n","      <th>lexile_category</th>\n","      <th>awsl</th>\n","      <th>toefl</th>\n","      <th>tsl</th>\n","      <th>bsl</th>\n","      <th>ngsl_freq</th>\n","      <th>ngsl_sp_freq</th>\n","      <th>naver_priority</th>\n","      <th>lemmetized</th>\n","      <th>proper_noun</th>\n","      <th>word_level</th>\n","    </tr>\n","    <tr>\n","      <th>Word</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>a</th>\n","      <td>NN</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>NN</td>\n","      <td>Y</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>A1</td>\n","      <td>A1</td>\n","      <td>2</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>aback</th>\n","      <td>NN</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>NN</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>B3</td>\n","      <td>C1</td>\n","      <td>0</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>4.0</td>\n","    </tr>\n","    <tr>\n","      <th>abacus</th>\n","      <td>NN</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>NN</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>C3</td>\n","      <td>C3</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>4.0</td>\n","    </tr>\n","    <tr>\n","      <th>abalone</th>\n","      <td>NN</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>NN</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>C3</td>\n","      <td>NN</td>\n","      <td>0</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>6.0</td>\n","    </tr>\n","    <tr>\n","      <th>abandon</th>\n","      <td>B2</td>\n","      <td>3000.0</td>\n","      <td>0.0</td>\n","      <td>NN</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>A2</td>\n","      <td>A3</td>\n","      <td>2</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>zygomorphic</th>\n","      <td>NN</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>NN</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>C4</td>\n","      <td>NN</td>\n","      <td>0</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>6.0</td>\n","    </tr>\n","    <tr>\n","      <th>zygosity</th>\n","      <td>NN</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>NN</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>C4</td>\n","      <td>NN</td>\n","      <td>0</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>6.0</td>\n","    </tr>\n","    <tr>\n","      <th>zygote</th>\n","      <td>NN</td>\n","      <td>0.0</td>\n","      <td>6.0</td>\n","      <td>science</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>C1</td>\n","      <td>C3</td>\n","      <td>0</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>5.0</td>\n","    </tr>\n","    <tr>\n","      <th>zygotic</th>\n","      <td>NN</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>NN</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>C3</td>\n","      <td>NN</td>\n","      <td>0</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>6.0</td>\n","    </tr>\n","    <tr>\n","      <th>émigré</th>\n","      <td>NN</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>NN</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>C2</td>\n","      <td>C2</td>\n","      <td>0</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>6.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>32738 rows × 14 columns</p>\n","</div>"],"text/plain":["            oxford_level  oxford_version  lexile_grade lexile_category awsl  \\\n","Word                                                                          \n","a                     NN             0.0           0.0              NN    Y   \n","aback                 NN             0.0           0.0              NN    N   \n","abacus                NN             0.0           0.0              NN    N   \n","abalone               NN             0.0           0.0              NN    N   \n","abandon               B2          3000.0           0.0              NN    N   \n","...                  ...             ...           ...             ...  ...   \n","zygomorphic           NN             0.0           0.0              NN    N   \n","zygosity              NN             0.0           0.0              NN    N   \n","zygote                NN             0.0           6.0         science    N   \n","zygotic               NN             0.0           0.0              NN    N   \n","émigré                NN             0.0           0.0              NN    N   \n","\n","            toefl tsl bsl ngsl_freq ngsl_sp_freq  naver_priority  lemmetized  \\\n","Word                                                                           \n","a               N   N   N        A1           A1               2        True   \n","aback           N   N   N        B3           C1               0       False   \n","abacus          N   N   N        C3           C3               1        True   \n","abalone         N   N   N        C3           NN               0        True   \n","abandon         N   N   N        A2           A3               2        True   \n","...           ...  ..  ..       ...          ...             ...         ...   \n","zygomorphic     N   N   N        C4           NN               0       False   \n","zygosity        N   N   N        C4           NN               0       False   \n","zygote          N   N   N        C1           C3               0        True   \n","zygotic         N   N   N        C3           NN               0       False   \n","émigré          N   N   N        C2           C2               0       False   \n","\n","            proper_noun  word_level  \n","Word                                 \n","a                 False         2.0  \n","aback             False         4.0  \n","abacus            False         4.0  \n","abalone           False         6.0  \n","abandon           False         2.0  \n","...                 ...         ...  \n","zygomorphic       False         6.0  \n","zygosity          False         6.0  \n","zygote            False         5.0  \n","zygotic           False         6.0  \n","émigré            False         6.0  \n","\n","[32738 rows x 14 columns]"]},"metadata":{},"output_type":"display_data"}],"source":["print(f'{origin_word_path}/words_levels_df.csv')\n","if os.path.exists(f'{origin_word_path}/words_levels_df.csv'):\n","    df_result = pd.read_csv(f'{origin_word_path}/words_levels_df.csv', index_col='Word')\n","    display(df_result)\n","else:\n","  print('not exists file');\n"]},{"cell_type":"markdown","metadata":{"id":"10pApwYwtsIQ"},"source":["## 단어 파일 불러와서 합치기"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":576},"executionInfo":{"elapsed":414,"status":"ok","timestamp":1634204560169,"user":{"displayName":"engs","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04651459774485874353"},"user_tz":-540},"id":"7KDBFO-q7WrD","outputId":"efa0b67e-8f50-4dfa-a975-e3fd654bcd01"},"outputs":[{"name":"stdout","output_type":"stream","text":["../words/raw_word_data/new/cam_A1.csv\n","../words/raw_word_data/new/cam_A2.csv\n","../words/raw_word_data/new/cam_B1.csv\n","../words/raw_word_data/new/cam_B2.csv\n","../words/raw_word_data/new/cam_C1.csv\n","../words/raw_word_data/new/cam_C2.csv\n"]},{"data":{"text/plain":["15385"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>camb_level</th>\n","    </tr>\n","    <tr>\n","      <th>Word</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>clothes</th>\n","      <td>A1</td>\n","    </tr>\n","    <tr>\n","      <th>twelve</th>\n","      <td>A1</td>\n","    </tr>\n","    <tr>\n","      <th>two</th>\n","      <td>A1</td>\n","    </tr>\n","    <tr>\n","      <th>to</th>\n","      <td>A1</td>\n","    </tr>\n","    <tr>\n","      <th>twenty</th>\n","      <td>A1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>with bated breath</th>\n","      <td>C2</td>\n","    </tr>\n","    <tr>\n","      <th>be lost for words</th>\n","      <td>C2</td>\n","    </tr>\n","    <tr>\n","      <th>by word of mouth</th>\n","      <td>C2</td>\n","    </tr>\n","    <tr>\n","      <th>not be the end of the world</th>\n","      <td>C2</td>\n","    </tr>\n","    <tr>\n","      <th>get/start off on the wrong foot</th>\n","      <td>C2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>15385 rows × 1 columns</p>\n","</div>"],"text/plain":["                                camb_level\n","Word                                      \n","clothes                                 A1\n","twelve                                  A1\n","two                                     A1\n","to                                      A1\n","twenty                                  A1\n","...                                    ...\n","with bated breath                       C2\n","be lost for words                       C2\n","by word of mouth                        C2\n","not be the end of the world             C2\n","get/start off on the wrong foot         C2\n","\n","[15385 rows x 1 columns]"]},"metadata":{},"output_type":"display_data"}],"source":["levels = ['A1', 'A2', 'B1', 'B2', 'C1', 'C2']\n","df_camb = pd.DataFrame()\n","count = 0\n","for level in levels:\n","  file_name = f'{camb_word_path}/cam_{level}.csv' \n","  print(f'{camb_word_path}/cam_{level}.csv')\n","  if os.path.exists(file_name):\n","    df = pd.read_csv(file_name, sep='\\t', header=None)\n","    df.rename(columns={0:'Word', 2: 'camb_level'}, inplace=True)\n","    df.set_index('Word', inplace=True)\n","    df.drop(columns=[1, 3, 4, 5], axis=1, inplace=True)\n","    df_camb = pd.concat([df_camb, df])\n","    count += len(df)\n","  else:\n","    print('not exists file');\n","\n","display(count, df_camb)\n"]},{"cell_type":"markdown","metadata":{"id":"H021-tI_DmHy"},"source":["## 소문자로 변형"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":450},"executionInfo":{"elapsed":34,"status":"ok","timestamp":1634204560170,"user":{"displayName":"engs","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04651459774485874353"},"user_tz":-540},"id":"lX97LlIwDn8e","outputId":"33c7f692-c41f-466b-82d9-28363f238c81"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>camb_level</th>\n","    </tr>\n","    <tr>\n","      <th>Word</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>clothes</th>\n","      <td>A1</td>\n","    </tr>\n","    <tr>\n","      <th>twelve</th>\n","      <td>A1</td>\n","    </tr>\n","    <tr>\n","      <th>two</th>\n","      <td>A1</td>\n","    </tr>\n","    <tr>\n","      <th>to</th>\n","      <td>A1</td>\n","    </tr>\n","    <tr>\n","      <th>twenty</th>\n","      <td>A1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>with bated breath</th>\n","      <td>C2</td>\n","    </tr>\n","    <tr>\n","      <th>be lost for words</th>\n","      <td>C2</td>\n","    </tr>\n","    <tr>\n","      <th>by word of mouth</th>\n","      <td>C2</td>\n","    </tr>\n","    <tr>\n","      <th>not be the end of the world</th>\n","      <td>C2</td>\n","    </tr>\n","    <tr>\n","      <th>get/start off on the wrong foot</th>\n","      <td>C2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>15385 rows × 1 columns</p>\n","</div>"],"text/plain":["                                camb_level\n","Word                                      \n","clothes                                 A1\n","twelve                                  A1\n","two                                     A1\n","to                                      A1\n","twenty                                  A1\n","...                                    ...\n","with bated breath                       C2\n","be lost for words                       C2\n","by word of mouth                        C2\n","not be the end of the world             C2\n","get/start off on the wrong foot         C2\n","\n","[15385 rows x 1 columns]"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["df_camb.index = df_camb.index.str.lower()\n","df_camb"]},{"cell_type":"markdown","metadata":{"id":"0ZfFyVPDERIQ"},"source":["## sth, sb 제거"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":450},"executionInfo":{"elapsed":31,"status":"ok","timestamp":1634204560171,"user":{"displayName":"engs","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04651459774485874353"},"user_tz":-540},"id":"g3dUoSZFE-jf","outputId":"6d71b840-4dfe-4c5b-8f02-f117abf6e5f0"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>camb_level</th>\n","    </tr>\n","    <tr>\n","      <th>Word</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>clothes</th>\n","      <td>A1</td>\n","    </tr>\n","    <tr>\n","      <th>twelve</th>\n","      <td>A1</td>\n","    </tr>\n","    <tr>\n","      <th>two</th>\n","      <td>A1</td>\n","    </tr>\n","    <tr>\n","      <th>to</th>\n","      <td>A1</td>\n","    </tr>\n","    <tr>\n","      <th>twenty</th>\n","      <td>A1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>with bated breath</th>\n","      <td>C2</td>\n","    </tr>\n","    <tr>\n","      <th>be lost for words</th>\n","      <td>C2</td>\n","    </tr>\n","    <tr>\n","      <th>by word of mouth</th>\n","      <td>C2</td>\n","    </tr>\n","    <tr>\n","      <th>not be the end of the world</th>\n","      <td>C2</td>\n","    </tr>\n","    <tr>\n","      <th>get/start off on the wrong foot</th>\n","      <td>C2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>14007 rows × 1 columns</p>\n","</div>"],"text/plain":["                                camb_level\n","Word                                      \n","clothes                                 A1\n","twelve                                  A1\n","two                                     A1\n","to                                      A1\n","twenty                                  A1\n","...                                    ...\n","with bated breath                       C2\n","be lost for words                       C2\n","by word of mouth                        C2\n","not be the end of the world             C2\n","get/start off on the wrong foot         C2\n","\n","[14007 rows x 1 columns]"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["processed_df_camb = df_camb[~df_camb.index.str.contains('sth')]\n","processed_df_camb = processed_df_camb[~processed_df_camb.index.str.contains('sb')]\n","processed_df_camb"]},{"cell_type":"markdown","metadata":{"id":"VtmiK9wMFyjN"},"source":["## 특수문자(공백 제외) 제거"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":450},"executionInfo":{"elapsed":30,"status":"ok","timestamp":1634204560173,"user":{"displayName":"engs","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04651459774485874353"},"user_tz":-540},"id":"yu4iZBQiF0Gl","outputId":"48bb6f24-da68-4202-f9fa-649622adbae7"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>camb_level</th>\n","    </tr>\n","    <tr>\n","      <th>Word</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>clothes</th>\n","      <td>A1</td>\n","    </tr>\n","    <tr>\n","      <th>twelve</th>\n","      <td>A1</td>\n","    </tr>\n","    <tr>\n","      <th>two</th>\n","      <td>A1</td>\n","    </tr>\n","    <tr>\n","      <th>to</th>\n","      <td>A1</td>\n","    </tr>\n","    <tr>\n","      <th>twenty</th>\n","      <td>A1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>with your bare hands</th>\n","      <td>C2</td>\n","    </tr>\n","    <tr>\n","      <th>with bated breath</th>\n","      <td>C2</td>\n","    </tr>\n","    <tr>\n","      <th>be lost for words</th>\n","      <td>C2</td>\n","    </tr>\n","    <tr>\n","      <th>by word of mouth</th>\n","      <td>C2</td>\n","    </tr>\n","    <tr>\n","      <th>not be the end of the world</th>\n","      <td>C2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>13176 rows × 1 columns</p>\n","</div>"],"text/plain":["                            camb_level\n","Word                                  \n","clothes                             A1\n","twelve                              A1\n","two                                 A1\n","to                                  A1\n","twenty                              A1\n","...                                ...\n","with your bare hands                C2\n","with bated breath                   C2\n","be lost for words                   C2\n","by word of mouth                    C2\n","not be the end of the world         C2\n","\n","[13176 rows x 1 columns]"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["processed_df_camb = processed_df_camb[~processed_df_camb.index.str.contains(r'[^a-zA-Z0-9\\ ]', regex=True)]\n","processed_df_camb\n"]},{"cell_type":"markdown","metadata":{"id":"GagRCykmNDlG"},"source":["## df_camb에서 중복 데이터 삭제"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":450},"executionInfo":{"elapsed":334,"status":"ok","timestamp":1634205802482,"user":{"displayName":"engs","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04651459774485874353"},"user_tz":-540},"id":"ED_OYjP-NF0l","outputId":"8ccb5a44-c6e3-4b22-d03d-4d9dfdeaa32e"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>camb_level</th>\n","    </tr>\n","    <tr>\n","      <th>Word</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>clothes</th>\n","      <td>A1</td>\n","    </tr>\n","    <tr>\n","      <th>twelve</th>\n","      <td>A1</td>\n","    </tr>\n","    <tr>\n","      <th>two</th>\n","      <td>A1</td>\n","    </tr>\n","    <tr>\n","      <th>twenty</th>\n","      <td>A1</td>\n","    </tr>\n","    <tr>\n","      <th>three</th>\n","      <td>A1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>with your bare hands</th>\n","      <td>C2</td>\n","    </tr>\n","    <tr>\n","      <th>with bated breath</th>\n","      <td>C2</td>\n","    </tr>\n","    <tr>\n","      <th>be lost for words</th>\n","      <td>C2</td>\n","    </tr>\n","    <tr>\n","      <th>by word of mouth</th>\n","      <td>C2</td>\n","    </tr>\n","    <tr>\n","      <th>not be the end of the world</th>\n","      <td>C2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>7747 rows × 1 columns</p>\n","</div>"],"text/plain":["                            camb_level\n","Word                                  \n","clothes                             A1\n","twelve                              A1\n","two                                 A1\n","twenty                              A1\n","three                               A1\n","...                                ...\n","with your bare hands                C2\n","with bated breath                   C2\n","be lost for words                   C2\n","by word of mouth                    C2\n","not be the end of the world         C2\n","\n","[7747 rows x 1 columns]"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["drop_duplicates_df_camb = processed_df_camb.reset_index()\n","drop_duplicates_df_camb = drop_duplicates_df_camb.drop_duplicates('Word', keep='last')\n","drop_duplicates_df_camb.set_index('Word', drop=True, inplace=True)\n","drop_duplicates_df_camb"]},{"cell_type":"markdown","metadata":{"id":"ibrOPFe_tsIZ"},"source":["## df_result에 df_camb 추가"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":521},"executionInfo":{"elapsed":261,"status":"ok","timestamp":1634205806373,"user":{"displayName":"engs","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04651459774485874353"},"user_tz":-540},"id":"kNE9-RmBtsIa","outputId":"62451f2e-02e0-46f5-b8cb-4fc1d752087b"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>oxford_level</th>\n","      <th>oxford_version</th>\n","      <th>lexile_grade</th>\n","      <th>lexile_category</th>\n","      <th>awsl</th>\n","      <th>toefl</th>\n","      <th>tsl</th>\n","      <th>bsl</th>\n","      <th>ngsl_freq</th>\n","      <th>ngsl_sp_freq</th>\n","      <th>naver_priority</th>\n","      <th>lemmetized</th>\n","      <th>proper_noun</th>\n","      <th>word_level</th>\n","      <th>camb_level</th>\n","    </tr>\n","    <tr>\n","      <th>Word</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>a</th>\n","      <td>NN</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>NN</td>\n","      <td>Y</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>A1</td>\n","      <td>A1</td>\n","      <td>2.0</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>2.0</td>\n","      <td>A2</td>\n","    </tr>\n","    <tr>\n","      <th>a bit</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>B2</td>\n","    </tr>\n","    <tr>\n","      <th>a bone of contention</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>C2</td>\n","    </tr>\n","    <tr>\n","      <th>a breath of fresh air</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>C2</td>\n","    </tr>\n","    <tr>\n","      <th>a broken heart</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>B2</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>zygomorphic</th>\n","      <td>NN</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>NN</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>C4</td>\n","      <td>NN</td>\n","      <td>0.0</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>6.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>zygosity</th>\n","      <td>NN</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>NN</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>C4</td>\n","      <td>NN</td>\n","      <td>0.0</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>6.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>zygote</th>\n","      <td>NN</td>\n","      <td>0.0</td>\n","      <td>6.0</td>\n","      <td>science</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>C1</td>\n","      <td>C3</td>\n","      <td>0.0</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>5.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>zygotic</th>\n","      <td>NN</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>NN</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>C3</td>\n","      <td>NN</td>\n","      <td>0.0</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>6.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>émigré</th>\n","      <td>NN</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>NN</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>C2</td>\n","      <td>C2</td>\n","      <td>0.0</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>6.0</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>34307 rows × 15 columns</p>\n","</div>"],"text/plain":["                      oxford_level  oxford_version  lexile_grade  \\\n","Word                                                               \n","a                               NN             0.0           0.0   \n","a bit                          NaN             NaN           NaN   \n","a bone of contention           NaN             NaN           NaN   \n","a breath of fresh air          NaN             NaN           NaN   \n","a broken heart                 NaN             NaN           NaN   \n","...                            ...             ...           ...   \n","zygomorphic                     NN             0.0           0.0   \n","zygosity                        NN             0.0           0.0   \n","zygote                          NN             0.0           6.0   \n","zygotic                         NN             0.0           0.0   \n","émigré                          NN             0.0           0.0   \n","\n","                      lexile_category awsl toefl  tsl  bsl ngsl_freq  \\\n","Word                                                                   \n","a                                  NN    Y     N    N    N        A1   \n","a bit                             NaN  NaN   NaN  NaN  NaN       NaN   \n","a bone of contention              NaN  NaN   NaN  NaN  NaN       NaN   \n","a breath of fresh air             NaN  NaN   NaN  NaN  NaN       NaN   \n","a broken heart                    NaN  NaN   NaN  NaN  NaN       NaN   \n","...                               ...  ...   ...  ...  ...       ...   \n","zygomorphic                        NN    N     N    N    N        C4   \n","zygosity                           NN    N     N    N    N        C4   \n","zygote                        science    N     N    N    N        C1   \n","zygotic                            NN    N     N    N    N        C3   \n","émigré                             NN    N     N    N    N        C2   \n","\n","                      ngsl_sp_freq  naver_priority lemmetized proper_noun  \\\n","Word                                                                        \n","a                               A1             2.0       True       False   \n","a bit                          NaN             NaN        NaN         NaN   \n","a bone of contention           NaN             NaN        NaN         NaN   \n","a breath of fresh air          NaN             NaN        NaN         NaN   \n","a broken heart                 NaN             NaN        NaN         NaN   \n","...                            ...             ...        ...         ...   \n","zygomorphic                     NN             0.0      False       False   \n","zygosity                        NN             0.0      False       False   \n","zygote                          C3             0.0       True       False   \n","zygotic                         NN             0.0      False       False   \n","émigré                          C2             0.0      False       False   \n","\n","                       word_level camb_level  \n","Word                                          \n","a                             2.0         A2  \n","a bit                         NaN         B2  \n","a bone of contention          NaN         C2  \n","a breath of fresh air         NaN         C2  \n","a broken heart                NaN         B2  \n","...                           ...        ...  \n","zygomorphic                   6.0        NaN  \n","zygosity                      6.0        NaN  \n","zygote                        5.0        NaN  \n","zygotic                       6.0        NaN  \n","émigré                        6.0        NaN  \n","\n","[34307 rows x 15 columns]"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["df_temp = df_result.join(drop_duplicates_df_camb, how='outer')\n","df_temp"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["df_temp.to_csv(f'{origin_word_path}/words_levels_df_211015.csv')"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"cambridge_processing.ipynb","provenance":[]},"interpreter":{"hash":"35d30bfe3f18c4671b7954a03b3607fce425614d47b33637e4d79a7acdaed77c"},"kernelspec":{"display_name":"Python 3.9.7 64-bit ('ott2': conda)","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
