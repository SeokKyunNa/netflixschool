{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import pandas as pd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# lemmas의 개수가 달라서 컬럼 숫자가 다름. 그로인한 오류를 방지하기 위해 일단 컬럼수를 50으로 잡아줌\n",
    "bsl_df = pd.read_csv(\"./raw_data/BSL_1.01_lemmatized_for_research.csv\", header=None, names=range(50))\n",
    "# 컬럼 전체가 NaN인 컬럼은 떨궈줌\n",
    "bsl_df = bsl_df.dropna(axis=1, how='all') \n",
    "# NaN 값을 '' 로 바꾼후 word1;word2;word3 로 컬럼 저장\n",
    "bsl_df = bsl_df.fillna('')\n",
    "bsl_df['Lemmas'] = bsl_df[list(range(1, 14))].agg(';'.join, axis=1).str.rstrip(';')\n",
    "bsl_df = bsl_df.rename(columns={0: \"Word\"})\n",
    "# Word, Lemmas 컬럼 빼고 다 떨궈줌\n",
    "bsl_df = bsl_df.drop(bsl_df.columns.difference(['Word', 'Lemmas']), 1)\n",
    "bsl_df.to_csv(\"bsl_with_lemmas.csv\", index=False)\n",
    "\n",
    "# row = bsl_df[~bsl_df[13].isnull()]\n",
    "\n",
    "bsl_df\n",
    "# bsl_df.to_csv(\"bsl_with_lemmas.csv\", index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tfl_df = pd.read_csv(\"./raw_data/toeflw.csv\")\n",
    "tfl_df = tfl_df.drop(tfl_df.columns.difference(['Word']), 1)\n",
    "\n",
    "tfl_df = tfl_df.sort_values('Word')\n",
    "tfl_df\n",
    "# tfl_df.to_csv(\"toefl_with_lemmas.csv\", index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# lemmas의 개수가 달라서 컬럼 숫자가 다름. 그로인한 오류를 방지하기 위해 일단 컬럼수를 50으로 잡아줌\n",
    "tsl_df = pd.read_csv(\"./raw_data/TSL_1.1_lemmatized_for_research.csv\", header=None, names=range(50))\n",
    "# 컬럼 전체가 NaN인 컬럼은 떨궈줌\n",
    "tsl_df = tsl_df.dropna(axis=1, how='all') \n",
    "# NaN 값을 '' 로 바꾼후 word1;word2;word3 로 컬럼 저장\n",
    "tsl_df = tsl_df.fillna('')\n",
    "tsl_df['Lemmas'] = tsl_df[list(range(1, 11))].agg(';'.join, axis=1).str.rstrip(';')\n",
    "tsl_df = tsl_df.rename(columns={0: \"Word\"})\n",
    "# # Word, Lemmas 컬럼 빼고 다 떨궈줌\n",
    "tsl_df = tsl_df.drop(tsl_df.columns.difference(['Word', 'Lemmas']), 1)\n",
    "\n",
    "# # row = tsl_df[~tsl_df[13].isnull()]\n",
    "\n",
    "tsl_df\n",
    "# tsl_df.to_csv(\"tsl_with_lemmas.csv\", index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "lemma_df = pd.read_csv(\"./raw_data/lemma.en.txt\", sep=\"->\", header=None, names=[\"Head\", \"Lemmas\"])\n",
    "lemma_df['Head'] = lemma_df['Head'].apply(lambda w: w.split(\"/\")[0]).str.strip()\n",
    "lemma_df['Lemmas'] = lemma_df['Lemmas'].str.strip()\n",
    "\n",
    "a = lemma_df.loc[84479][\"Head\"]\n",
    "b = lemma_df.loc[84479][\"Lemmas\"]\n",
    "print([a])\n",
    "print([b])\n",
    "\n",
    "# lemma_df\n",
    "\n",
    "# lemma_df.to_csv(\"entire_lemmas.csv\", index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# awsl_df = pd.read_csv(\"./words_refined/Dang,Coxhead.csv\")\n",
    "# awsl_df['Word'] = awsl_df['Word'].str.strip()\n",
    "# awsl_df['Lemmas'] = awsl_df['Lemmas'].str.strip().str.strip(';').str.replace(' ', '')\n",
    "\n",
    "# awsl_df\n",
    "\n",
    "# awsl_df.to_csv(\"awsl_with_lemmas.csv\", index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.min_rows', 100)\n",
    "\n",
    "ox = pd.read_csv(\"../raw_data/oxford_3000.txt\", header=None, sep=' ', names=range(50))\n",
    "ox = ox[ox[14].isnull()]\n",
    "ox = ox.dropna(axis=1, how='all') \n",
    "ox = ox.fillna('')\n",
    "ox\n",
    "# get normal words\n",
    "normal_condition = ox[1].str.contains(\".\", regex=False) & ~ox[0].str.contains(\"[^a-zA-Z]\")\n",
    "normal = ox[normal_condition]\n",
    "normal = normal[[0]]\n",
    "normal\n",
    "\n",
    "# exceptions\n",
    "ex = ox[~normal_condition]\n",
    "ex\n",
    "# add levels to normal\n",
    "levels = ox[ox[0].isin(['A1', 'A2', 'B1', 'B2'])]\n",
    "levels\n",
    "ex = ex[~ex[0].isin(['A1', 'A2', 'B1', 'B2'])]\n",
    "ex\n",
    "normal = normal.append(levels[[0]])\n",
    "normal\n",
    "normal.sort_index(inplace=True)\n",
    "\n",
    "### exceptions 처리\n",
    "numbers = ex[ex[1] == 'number']\n",
    "numbers\n",
    "normal = normal.append(numbers[[0]])\n",
    "normal\n",
    "ex = ex[~(ex[1] == 'number')]\n",
    "ex\n",
    "\n",
    "ones = ex[ex[0].str.len() == 1]\n",
    "ex = ex[~(ex[0].str.len() == 1)]\n",
    "ex = ex[~(ex[0].str.len() == 0)]\n",
    "ex\n",
    "\n",
    "ex[0] = ex[0].apply(lambda x: x[:-1] if x[-1].isdigit() else x)\n",
    "ex\n",
    "ex = ex.drop_duplicates(subset=0)\n",
    "ex\n",
    "# ex = ex.drop([1, 351, 438, 930, 517, 912])\n",
    "ex = ex.drop([1, 350, 434, 929, 516, 911, 670])\n",
    "ex\n",
    "\n",
    "compounds = ex[~ex[1].str.contains(\"[^a-zA-Z]\")]\n",
    "compounds\n",
    "compounds = compounds[(compounds[1] !='') & (compounds[1] != 'modal')].drop([779, 2846])\n",
    "compounds\n",
    "compounds[0] = compounds[0] + ' ' + compounds[1]\n",
    "compounds\n",
    "ex.update(compounds)\n",
    "ex\n",
    "\n",
    "# combine to normal\n",
    "normal = normal.append(ex[[0]])\n",
    "normal\n",
    "normal[0] = normal[0].str.lower()\n",
    "normal\n",
    "# drop duplicates to easy version\n",
    "normal.sort_index(inplace=True)\n",
    "normal.drop_duplicates(subset=0, inplace=True)\n",
    "\n",
    "### slice by level\n",
    "normal = normal.rename(columns={0:'Word'})\n",
    "normal\n",
    "normal.reset_index(inplace=True)\n",
    "normal\n",
    "normal = normal.drop(columns='index')\n",
    "normal\n",
    "indices = normal[normal.Word.isin(['a1', 'a2', 'b1', 'b2'])]\n",
    "indices\n",
    "a1 = normal.loc[1:895]\n",
    "a2 = normal.loc[897:1686]\n",
    "b1 = normal.loc[1688:2376]\n",
    "b2 = normal.loc[2378:]\n",
    "\n",
    "a1['Level'] = 'A1'\n",
    "a2['Level'] = 'A2'\n",
    "b1['Level'] = 'B1'\n",
    "b2['Level'] = 'B2'\n",
    "\n",
    "final_df_3000 = pd.concat([a1, a2, b1, b2])\n",
    "final_df_3000['Version'] = 3000\n",
    "final_df_3000\n",
    "\n",
    "# final_df_3000.to_csv(\"ox_3000_american.csv\", index=False)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/var/folders/qz/yv1t73k93pv_4cwl9gbygk0w0000gn/T/ipykernel_40470/3862471014.py:80: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  a1['Level'] = 'A1'\n",
      "/var/folders/qz/yv1t73k93pv_4cwl9gbygk0w0000gn/T/ipykernel_40470/3862471014.py:81: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  a2['Level'] = 'A2'\n",
      "/var/folders/qz/yv1t73k93pv_4cwl9gbygk0w0000gn/T/ipykernel_40470/3862471014.py:82: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  b1['Level'] = 'B1'\n",
      "/var/folders/qz/yv1t73k93pv_4cwl9gbygk0w0000gn/T/ipykernel_40470/3862471014.py:83: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  b2['Level'] = 'B2'\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "source": [
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.min_rows', 100)\n",
    "\n",
    "ox = pd.read_csv(\"../raw_data/oxford_5000.txt\", header=None, sep=' ', names=range(50))\n",
    "ox = ox[ox[14].isnull()]\n",
    "ox = ox.dropna(axis=1, how='all') \n",
    "ox\n",
    "ox = ox.fillna('')\n",
    "ox\n",
    "# get normal words\n",
    "normal_condition = ox[1].str.contains(\".\", regex=False) & ~ox[0].str.contains(\"[^a-zA-Z]\")\n",
    "normal = ox[normal_condition]\n",
    "normal = normal[[0]]\n",
    "normal\n",
    "\n",
    "# exceptions\n",
    "ex = ox[~normal_condition]\n",
    "ex\n",
    "# add levels to normal\n",
    "levels = ox[ox[0].isin(['B2', 'C1'])]\n",
    "levels\n",
    "ex = ex[~ex[0].isin(['B2', 'C1'])]\n",
    "ex\n",
    "normal = normal.append(levels[[0]])\n",
    "normal\n",
    "normal.sort_index(inplace=True)\n",
    "\n",
    "### exceptions 처리\n",
    "numbers = ex[ex[1] == 'number']\n",
    "numbers\n",
    "normal = normal.append(numbers[[0]])\n",
    "normal\n",
    "ex = ex[~(ex[1] == 'number')]\n",
    "ex\n",
    "\n",
    "ones = ex[ex[0].str.len() == 1]\n",
    "ex = ex[~(ex[0].str.len() == 1)]\n",
    "ex = ex[~(ex[0].str.len() == 0)]\n",
    "ex\n",
    "\n",
    "ex[0] = ex[0].apply(lambda x: x[:-1] if x[-1].isdigit() else x)\n",
    "ex\n",
    "ex = ex.drop_duplicates(subset=0)\n",
    "ex\n",
    "\n",
    "# combine to normal\n",
    "normal = normal.append(ex[[0]])\n",
    "normal\n",
    "normal[0] = normal[0].str.lower()\n",
    "normal\n",
    "# drop duplicates to easy version\n",
    "normal.sort_index(inplace=True)\n",
    "normal.drop_duplicates(subset=0, inplace=True)\n",
    "normal\n",
    "\n",
    "### slice by level\n",
    "normal = normal.rename(columns={0:'Word'})\n",
    "normal\n",
    "normal.reset_index(inplace=True)\n",
    "normal\n",
    "normal = normal.drop(columns='index')\n",
    "normal\n",
    "indices = normal[normal.Word.isin(['b2', 'c1'])]\n",
    "indices\n",
    "b2 = normal.loc[1:700]\n",
    "c1 = normal.loc[702:]\n",
    "b2['Level'] = 'B2'\n",
    "c1['Level'] = 'C1'\n",
    "\n",
    "final_df_5000 = pd.concat([b2, c1])\n",
    "final_df_5000['Version'] = 5000\n",
    "final_df_5000\n",
    "\n",
    "# final_df_5000.to_csv(\"ox_5000_american.csv\", index=False)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/var/folders/qz/yv1t73k93pv_4cwl9gbygk0w0000gn/T/ipykernel_40470/963181386.py:67: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  b2['Level'] = 'B2'\n",
      "/var/folders/qz/yv1t73k93pv_4cwl9gbygk0w0000gn/T/ipykernel_40470/963181386.py:68: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  c1['Level'] = 'C1'\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('ott2': conda)"
  },
  "interpreter": {
   "hash": "1e4a953aa74ba58e7f4e54a6e7ab1761f2dc5a400c27d8a75d79b1831ff902de"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}