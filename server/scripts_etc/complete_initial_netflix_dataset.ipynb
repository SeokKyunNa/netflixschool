{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', 10)\n",
    "\n",
    "s3 = boto3.resource('s3')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "bucket = s3.Bucket('netflixschool')\n",
    "for item in bucket.objects.all():\n",
    "  print(item)\n",
    "\n",
    "  # https://netflixschool.s3.amazonaws.com/넷플릭스쿨_로고.png"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create poster image bucket"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# s3.create_bucket(Bucket='netflixschool-posters')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "s3 = boto3.resource('s3')\n",
    "for bucket in s3.buckets.all():\n",
    "    print(bucket.name)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 넷플릭스 데이터셋 불러오기"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "netflix_data = pd.read_csv('../csv_files/netflix_contents_korean.csv')\n",
    "netflix_data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Add images to S3"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os\n",
    "path = os.path.dirname(os.path.abspath('/Users/yuliejung/dev/ott2/data_preprocessing/img/poster/Morning.Glory_Poster.jpg'))\n",
    "\n",
    "print(path)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# for index, row in netflix_data.iterrows():\n",
    "#   title = row['title']\n",
    "#   year= row['release_year']\n",
    "#   name = f'{title}_{str(year)}.jpg'\n",
    "#   imgpath = f'{path}/{title}_Poster.jpg'\n",
    "#   with open(imgpath, 'rb') as image:\n",
    "#     try:\n",
    "#       s3.Bucket('netflixschool-posters').put_object(Key=name, Body=image, ContentType='image/jpeg')\n",
    "#       url = 'https://netflixschool-posters.s3.amazonaws.com/' + name\n",
    "#       netflix_data.loc[index, 'img_path'] = url\n",
    "#       print(url)\n",
    "#     except Exception as e:\n",
    "#       print(name)\n",
    "#       print(e)\n",
    "#       continue"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# bucket = s3.Bucket('netflixschool-posters')\n",
    "# for item in bucket.objects.all():\n",
    "#   print(item)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# s3.Object('netflixschool-posters', 'About.Time_2013_poster.jpg').delete()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pd.set_option('display.max_rows', 10)\n",
    "\n",
    "# netflix_data[['title','img_path']]\n",
    "netflix_data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "netflix_data_clean = netflix_data.drop(45)\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "netflix_data_clean[['title', 'img_path', 'title_kr']]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## add script_csv to s3"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "path = os.path.dirname(os.path.abspath('/Users/yuliejung/dev/ott2/data_preprocessing/script/Documentary'))\n",
    "# path = os.path.dirname(os.path.abspath('/Users/yuliejung/dev/ott2/data_preprocessing/script/Movie/About.Time/About.Time.WEBRip.Netflix.en[cc].csv'))\n",
    "\n",
    "print(path)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "source": [
    "# error_list = []\n",
    "\n",
    "# for index, row in netflix_data_clean.iterrows():\n",
    "#   if len(str(row['subs_path'])) > 5 :\n",
    "#     continue\n",
    "#   title = row['title']\n",
    "#   year= row['release_year']\n",
    "#   name = f'{title}_{str(year)}.csv'\n",
    "\n",
    "#   try:\n",
    "#     film_type = 'Documentary'\n",
    "#     csvpath = f'{path}/{film_type}/{title}/{title}.WEBRip.Netflix.en[cc].csv'\n",
    "#     csv = open(csvpath, 'rb')\n",
    "#   except FileNotFoundError as e:\n",
    "#     film_type = \"Movie\"\n",
    "#     csvpath = f'{path}/{film_type}/{title}/{title}.WEBRip.Netflix.en[cc].csv'\n",
    "#     try:\n",
    "#       csv = open(csvpath, 'rb')\n",
    "#     except FileNotFoundError as e:\n",
    "#       film_type = \"Drama\"\n",
    "#       csvpath = f'{path}/{film_type}/{title}/{title}.WEBRip.Netflix.en[cc].csv'\n",
    "#       try:\n",
    "#         csv = open(csvpath, 'rb')\n",
    "#       except Exception as e:\n",
    "#         print(e)\n",
    "#         error_list.append((index, title))\n",
    "#         continue\n",
    "\n",
    "#   if csv:\n",
    "#     try:\n",
    "#       s3.Bucket('netflixschool-script-csv').put_object(Key=name, Body=csv, ContentType='text/csv')\n",
    "#       url = 'https://netflixschool-script-csv.s3.amazonaws.com/' + name\n",
    "#       netflix_data_clean.loc[index, 'subs_path'] = url\n",
    "#       print(url)\n",
    "#     except Exception as e:\n",
    "#       print(e)\n",
    "#       print((index, title))\n",
    "#     finally:\n",
    "#       csv.close()\n",
    "#       continue\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "https://netflixschool-script-csv.s3.amazonaws.com/Anne.with.an.E_2017.csv\n",
      "https://netflixschool-script-csv.s3.amazonaws.com/Better.Call.Saul_2015.csv\n",
      "https://netflixschool-script-csv.s3.amazonaws.com/Black.Mirror_2011.csv\n",
      "https://netflixschool-script-csv.s3.amazonaws.com/Breaking.Bad_2008.csv\n",
      "https://netflixschool-script-csv.s3.amazonaws.com/Disenchantment_2018.csv\n",
      "https://netflixschool-script-csv.s3.amazonaws.com/Friends_1994.csv\n",
      "https://netflixschool-script-csv.s3.amazonaws.com/How.to.Get.Away.With.Murder_2014.csv\n",
      "https://netflixschool-script-csv.s3.amazonaws.com/MINDHUNTER_2017.csv\n",
      "https://netflixschool-script-csv.s3.amazonaws.com/Narcos_2015.csv\n",
      "https://netflixschool-script-csv.s3.amazonaws.com/Peaky.Blinders_2013.csv\n",
      "https://netflixschool-script-csv.s3.amazonaws.com/Rick.and.Morty_2013.csv\n",
      "https://netflixschool-script-csv.s3.amazonaws.com/Sherlock_2010.csv\n",
      "https://netflixschool-script-csv.s3.amazonaws.com/Stranger.Things_2016.csv\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "source": [
    "pd.set_option('display.max_colwidth', 10)\n",
    "\n",
    "netflix_data_clean\n",
    "# netflix_data_clean[netflix_data_clean['img_path'].isnull()]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>netflix_id</th>\n",
       "      <th>title</th>\n",
       "      <th>type</th>\n",
       "      <th>title_kr</th>\n",
       "      <th>title_en</th>\n",
       "      <th>genre</th>\n",
       "      <th>age_rating</th>\n",
       "      <th>director</th>\n",
       "      <th>release_year</th>\n",
       "      <th>running_time</th>\n",
       "      <th>story</th>\n",
       "      <th>subs_path</th>\n",
       "      <th>img_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [netflix_id, title, type, title_kr, title_en, genre, age_rating, director, release_year, running_time, story, subs_path, img_path]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "execution_count": 154
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Export data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "source": [
    "# netflix_data_clean.to_csv('../csv_files/netflix_content_initial_data.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Code to read CSV into pandas DF"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "bucket = \"netflixschool-script-csv\"\n",
    "file_name = name\n",
    "\n",
    "s3_client = boto3.client('s3') \n",
    "# 's3' is a key word. create connection to S3 using default config and all buckets within S3\n",
    "\n",
    "obj = s3_client.get_object(Bucket= bucket, Key= file_name) \n",
    "# get object and file (key) from bucket\n",
    "\n",
    "initial_df = pd.read_csv(obj['Body']) # 'Body' is a key word\n",
    "\n",
    "initial_df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Update some netflix data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "source": [
    "netflix_data = pd.read_csv(\"../csv_files/netflix_contents_complete_data.csv\")\n",
    "netflix_data_original = pd.read_csv('../csv_files/netflix_contents_crawled.csv')\n",
    "\n",
    "netflix_data_original.set_index('netflix_id', inplace=True)\n",
    "netflix_data_original = netflix_data_original[~netflix_data_original.index.duplicated(keep='first')]\n",
    "\n",
    "netflix_data.drop(columns='type', inplace=True)\n",
    "netflix_data.set_index('netflix_id', inplace=True)\n",
    "netflix_data['type'] = np.nan\n",
    "\n",
    "netflix_data.update(netflix_data_original)\n",
    "netflix_data\n",
    "\n",
    "netflix_data.type = netflix_data.type.apply(lambda x: 1 if x == 'Movie' else 2)\n",
    "netflix_data\n",
    "# netflix_data.to_csv('../csv_files/netflix_contents_with_types.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('ott2': conda)"
  },
  "interpreter": {
   "hash": "1e4a953aa74ba58e7f4e54a6e7ab1761f2dc5a400c27d8a75d79b1831ff902de"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}